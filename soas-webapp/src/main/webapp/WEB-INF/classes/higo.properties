#higo zookeeper
higo.zkConnectionString=10.253.93.71:2181,10.253.93.72:2181,10.253.93.73:2181,10.253.93.74:2181,10.253.93.75:2181
higo.sessionTimeout=5000
#test.groups用于测试环境，线上务必需要注释掉该值
#test.groups=10.227.4.150:61111,10.227.4.150:61112,10.227.4.150:61113,10.227.4.150:61114,10.227.4.150:61115,10.227.4.150:61116,10.227.4.150:61117,10.227.4.150:61118,10.227.4.150:61119,10.227.4.150:61120,10.227.4.151:61111,10.227.4.151:61112,10.227.4.151:61113,10.227.4.151:61114,10.227.4.151:61115,10.227.4.151:61116,10.227.4.151:61117,10.227.4.151:61118,10.227.4.151:61119,10.227.4.151:61120
##job scheduler configition
#scheduler.job.indexOutPathBase=/user/hadoop/datasharing/indexes/
##数据在hdfs上的路径，其子目录格式为dt=yyyymmdd
#scheduler.job.inputPathBase=/user/hadoop/datasharing/dws_crd_datasharing_dd
#scheduler.job.solrHome=/home/hadoop/peng.chen/deployer/trunk_datasharing/dist/higo-core/solr
#scheduler.job.solrHome=/home/hadoop/datasharing/higo/higo-core/solr
#scheduler.job.nameNodeUrl=hdfs://hbs03011.global.alipay.com:9000
#scheduler.job.jobTrackerUrl=hdfs://hbs03011.global.alipay.com:9001
#scheduler.job.isIndex=true
#scheduler.job.zKRoot=higo
#scheduler.job.projectName=datasharing
##如果无uniquekey, 则务必用scheduler.job.uniquekey=""
#scheduler.job.uniquekey=user_id
#scheduler.job.isUpdatemodel=false
#scheduler.job.shards=20
#scheduler.job.minFreeSpace=5242880
#queryScheduler 配置
#MAX_SIMPLE_QUERY_PRE=500
#MAX_GROUP_QUERY_PRE=5
#MAX_USER_QUERY=500
#MAX_THREAD_POOL=500